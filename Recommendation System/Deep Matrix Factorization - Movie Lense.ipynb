{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    ***** RECOMMENDATION SYSTEM USING DEEP MATRIX FACTORIZATION for Movie Rating *****\n",
    "\n",
    "A. This notebook has implementation of recommendation system for Movie Rating database using Deep Matrix Factorization technique\n",
    "    \n",
    "Note:  This has been referenced from opensource project.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "\n",
    "class DataSet(object):\n",
    "    def __init__(self, fileName):\n",
    "        self.data, self.shape = self.getData(fileName)\n",
    "        self.train, self.test = self.getTrainTest()\n",
    "        self.trainDict = self.getTrainDict()\n",
    "\n",
    "    def getData(self, fileName):\n",
    "        if fileName == 'ml-1m':\n",
    "            print(\"Loading ml-1m data set...\")\n",
    "            data = []\n",
    "            filePath = 'ratings.dat'\n",
    "            u = 0\n",
    "            i = 0\n",
    "            maxr = 0.0\n",
    "            with open(filePath, 'r') as f:\n",
    "                for line in f:\n",
    "                    if line:\n",
    "                        lines = line[:-1].split(\"::\")\n",
    "                        user = int(lines[0])\n",
    "                        movie = int(lines[1])\n",
    "                        score = float(lines[2])\n",
    "                        time = int(lines[3])\n",
    "                        data.append((user, movie, score, time))\n",
    "                        if user > u:\n",
    "                            u = user\n",
    "                        if movie > i:\n",
    "                            i = movie\n",
    "                        if score > maxr:\n",
    "                            maxr = score\n",
    "            self.maxRate = maxr\n",
    "            print(\"Loading Success!\\n\"\n",
    "                  \"Data Info:\\n\"\n",
    "                  \"\\tUser Num: {}\\n\"\n",
    "                  \"\\tItem Num: {}\\n\"\n",
    "                  \"\\tData Size: {}\".format(u, i, len(data)))\n",
    "            return data, [u, i]\n",
    "        else:\n",
    "            print(\"Current data set is not support!\")\n",
    "            sys.exit()\n",
    "\n",
    "    def getTrainTest(self):\n",
    "        data = self.data\n",
    "        data = sorted(data, key=lambda x: (x[0], x[3]))\n",
    "        train = []\n",
    "        test = []\n",
    "        for i in range(len(data)-1):\n",
    "            user = data[i][0]-1\n",
    "            item = data[i][1]-1\n",
    "            rate = data[i][2]\n",
    "            if data[i][0] != data[i+1][0]:\n",
    "                test.append((user, item, rate))\n",
    "            else:\n",
    "                train.append((user, item, rate))\n",
    "\n",
    "        test.append((data[-1][0]-1, data[-1][1]-1, data[-1][2]))\n",
    "        return train, test\n",
    "\n",
    "    def getTrainDict(self):\n",
    "        dataDict = {}\n",
    "        for i in self.train:\n",
    "            dataDict[(i[0], i[1])] = i[2]\n",
    "        return dataDict\n",
    "\n",
    "    def getEmbedding(self):\n",
    "        train_matrix = np.zeros([self.shape[0], self.shape[1]], dtype=np.float32)\n",
    "        for i in self.train:\n",
    "            user = i[0]\n",
    "            movie = i[1]\n",
    "            rating = i[2]\n",
    "            train_matrix[user][movie] = rating\n",
    "        return np.array(train_matrix)\n",
    "\n",
    "    def getInstances(self, data, negNum):\n",
    "        user = []\n",
    "        item = []\n",
    "        rate = []\n",
    "        for i in data:\n",
    "            user.append(i[0])\n",
    "            item.append(i[1])\n",
    "            rate.append(i[2])\n",
    "            for t in range(negNum):\n",
    "                j = np.random.randint(self.shape[1])\n",
    "                while (i[0], j) in self.trainDict:\n",
    "                    j = np.random.randint(self.shape[1])\n",
    "                user.append(i[0])\n",
    "                item.append(j)\n",
    "                rate.append(0.0)\n",
    "        return np.array(user), np.array(item), np.array(rate)\n",
    "\n",
    "    def getTestNeg(self, testData, negNum):\n",
    "        user = []\n",
    "        item = []\n",
    "        for s in testData:\n",
    "            tmp_user = []\n",
    "            tmp_item = []\n",
    "            u = s[0]\n",
    "            i = s[1]\n",
    "            tmp_user.append(u)\n",
    "            tmp_item.append(i)\n",
    "            neglist = set()\n",
    "            neglist.add(i)\n",
    "            for t in range(negNum):\n",
    "                j = np.random.randint(self.shape[1])\n",
    "                while (u, j) in self.trainDict or j in neglist:\n",
    "                    j = np.random.randint(self.shape[1])\n",
    "                neglist.add(j)\n",
    "                tmp_user.append(u)\n",
    "                tmp_item.append(j)\n",
    "            user.append(tmp_user)\n",
    "            item.append(tmp_item)\n",
    "        return [np.array(user), np.array(item)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import argparse\n",
    "import sys\n",
    "import os\n",
    "import heapq\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self):\n",
    "        self.dataName = 'ml-1m'\n",
    "        self.dataSet = DataSet(self.dataName)\n",
    "        self.shape = self.dataSet.shape\n",
    "        self.maxRate = self.dataSet.maxRate\n",
    "\n",
    "        self.train = self.dataSet.train\n",
    "        self.test = self.dataSet.test\n",
    "\n",
    "        self.negNum = 7\n",
    "        self.testNeg = self.dataSet.getTestNeg(self.test, 99)\n",
    "        self.add_embedding_matrix()\n",
    "\n",
    "        self.add_placeholders()\n",
    "\n",
    "        self.userLayer = [512, 64]\n",
    "        self.itemLayer = [1024, 64]\n",
    "        self.add_model()\n",
    "\n",
    "        self.add_loss()\n",
    "\n",
    "        self.lr = 0.0001\n",
    "        self.add_train_step()\n",
    "\n",
    "        self.checkPoint = './checkPoint/'\n",
    "        self.init_sess()\n",
    "\n",
    "        self.maxEpochs = 5\n",
    "        self.batchSize = 256\n",
    "\n",
    "        self.topK =10\n",
    "        self.earlyStop = 5\n",
    "\n",
    "\n",
    "    def add_placeholders(self):\n",
    "        self.user = tf.placeholder(tf.int32)\n",
    "        self.item = tf.placeholder(tf.int32)\n",
    "        self.rate = tf.placeholder(tf.float32)\n",
    "        self.drop = tf.placeholder(tf.float32)\n",
    "\n",
    "    def add_embedding_matrix(self):\n",
    "        self.user_item_embedding = tf.convert_to_tensor(self.dataSet.getEmbedding())\n",
    "        self.item_user_embedding = tf.transpose(self.user_item_embedding)\n",
    "\n",
    "    def add_model(self):\n",
    "        user_input = tf.nn.embedding_lookup(self.user_item_embedding, self.user)\n",
    "        item_input = tf.nn.embedding_lookup(self.item_user_embedding, self.item)\n",
    "\n",
    "        def init_variable(shape, name):\n",
    "            return tf.Variable(tf.truncated_normal(shape=shape, dtype=tf.float32, stddev=0.01), name=name)\n",
    "\n",
    "        with tf.name_scope(\"User_Layer\"):\n",
    "            user_W1 = init_variable([self.shape[1], self.userLayer[0]], \"user_W1\")\n",
    "            user_out = tf.matmul(user_input, user_W1)\n",
    "            for i in range(0, len(self.userLayer)-1):\n",
    "                W = init_variable([self.userLayer[i], self.userLayer[i+1]], \"user_W\"+str(i+2))\n",
    "                b = init_variable([self.userLayer[i+1]], \"user_b\"+str(i+2))\n",
    "                user_out = tf.nn.relu(tf.add(tf.matmul(user_out, W), b))\n",
    "\n",
    "        with tf.name_scope(\"Item_Layer\"):\n",
    "            item_W1 = init_variable([self.shape[0], self.itemLayer[0]], \"item_W1\")\n",
    "            item_out = tf.matmul(item_input, item_W1)\n",
    "            for i in range(0, len(self.itemLayer)-1):\n",
    "                W = init_variable([self.itemLayer[i], self.itemLayer[i+1]], \"item_W\"+str(i+2))\n",
    "                b = init_variable([self.itemLayer[i+1]], \"item_b\"+str(i+2))\n",
    "                item_out = tf.nn.relu(tf.add(tf.matmul(item_out, W), b))\n",
    "\n",
    "        norm_user_output = tf.sqrt(tf.reduce_sum(tf.square(user_out), axis=1))\n",
    "        norm_item_output = tf.sqrt(tf.reduce_sum(tf.square(item_out), axis=1))\n",
    "        self.y_ = tf.reduce_sum(tf.multiply(user_out, item_out), axis=1, keep_dims=False) / (norm_item_output* norm_user_output)\n",
    "        self.y_ = tf.maximum(1e-6, self.y_)\n",
    "\n",
    "    def add_loss(self):\n",
    "        regRate = self.rate / self.maxRate\n",
    "        losses = regRate * tf.log(self.y_) + (1 - regRate) * tf.log(1 - self.y_)\n",
    "        loss = -tf.reduce_sum(losses)\n",
    "        # regLoss = tf.add_n([tf.nn.l2_loss(v) for v in tf.trainable_variables()])\n",
    "        # self.loss = loss + self.reg * regLoss\n",
    "        self.loss = loss\n",
    "\n",
    "    def add_train_step(self):\n",
    "        '''\n",
    "        global_step = tf.Variable(0, name='global_step', trainable=False)\n",
    "        self.lr = tf.train.exponential_decay(self.lr, global_step,\n",
    "                                             self.decay_steps, self.decay_rate, staircase=True)\n",
    "        '''\n",
    "        optimizer = tf.train.AdamOptimizer(self.lr)\n",
    "        self.train_step = optimizer.minimize(self.loss)\n",
    "\n",
    "    def init_sess(self):\n",
    "        self.config = tf.ConfigProto()\n",
    "        self.config.gpu_options.allow_growth = True\n",
    "        self.config.allow_soft_placement = True\n",
    "        self.sess = tf.Session(config=self.config)\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "\n",
    "        self.saver = tf.train.Saver()\n",
    "        if os.path.exists(self.checkPoint):\n",
    "            [os.remove(f) for f in os.listdir(self.checkPoint)]\n",
    "        else:\n",
    "            os.mkdir(self.checkPoint)\n",
    "\n",
    "    def run(self):\n",
    "        best_hr = -1\n",
    "        best_NDCG = -1\n",
    "        best_epoch = -1\n",
    "        print(\"Start Training!\")\n",
    "        for epoch in range(self.maxEpochs):\n",
    "            print(\"=\"*20+\"Epoch \", epoch, \"=\"*20)\n",
    "            self.run_epoch(self.sess)\n",
    "            print('='*50)\n",
    "            print(\"Start Evaluation!\")\n",
    "            hr, NDCG = self.evaluate(self.sess, self.topK)\n",
    "            print(\"Epoch \", epoch, \"HR: {}, NDCG: {}\".format(hr, NDCG))\n",
    "            if hr > best_hr or NDCG > best_NDCG:\n",
    "                best_hr = hr\n",
    "                best_NDCG = NDCG\n",
    "                best_epoch = epoch\n",
    "                self.saver.save(self.sess, self.checkPoint)\n",
    "            if epoch - best_epoch > self.earlyStop:\n",
    "                print(\"Normal Early stop!\")\n",
    "                break\n",
    "            print(\"=\"*20+\"Epoch \", epoch, \"End\"+\"=\"*20)\n",
    "        print(\"Best hr: {}, NDCG: {}, At Epoch {}\".format(best_hr, best_NDCG, best_epoch))\n",
    "        print(\"Training complete!\")\n",
    "\n",
    "    def run_epoch(self, sess, verbose=10):\n",
    "        train_u, train_i, train_r = self.dataSet.getInstances(self.train, self.negNum)\n",
    "        train_len = len(train_u)\n",
    "        shuffled_idx = np.random.permutation(np.arange(train_len))\n",
    "        train_u = train_u[shuffled_idx]\n",
    "        train_i = train_i[shuffled_idx]\n",
    "        train_r = train_r[shuffled_idx]\n",
    "\n",
    "        num_batches = len(train_u) // self.batchSize + 1\n",
    "\n",
    "        losses = []\n",
    "        for i in range(num_batches):\n",
    "            min_idx = i * self.batchSize\n",
    "            max_idx = np.min([train_len, (i+1)*self.batchSize])\n",
    "            train_u_batch = train_u[min_idx: max_idx]\n",
    "            train_i_batch = train_i[min_idx: max_idx]\n",
    "            train_r_batch = train_r[min_idx: max_idx]\n",
    "\n",
    "            feed_dict = self.create_feed_dict(train_u_batch, train_i_batch, train_r_batch)\n",
    "            _, tmp_loss = sess.run([self.train_step, self.loss], feed_dict=feed_dict)\n",
    "            losses.append(tmp_loss)\n",
    "            if verbose and i % verbose == 0:\n",
    "                sys.stdout.write('\\r{} / {} : loss = {}'.format(\n",
    "                    i, num_batches, np.mean(losses[-verbose:])\n",
    "                ))\n",
    "                sys.stdout.flush()\n",
    "        loss = np.mean(losses)\n",
    "        print(\"\\nMean loss in this epoch is: {}\".format(loss))\n",
    "        return loss\n",
    "\n",
    "    def create_feed_dict(self, u, i, r=None, drop=None):\n",
    "        return {self.user: u,\n",
    "                self.item: i,\n",
    "                self.rate: r,\n",
    "                self.drop: drop}\n",
    "\n",
    "    def evaluate(self, sess, topK):\n",
    "        def getHitRatio(ranklist, targetItem):\n",
    "            for item in ranklist:\n",
    "                if item == targetItem:\n",
    "                    return 1\n",
    "            return 0\n",
    "        def getNDCG(ranklist, targetItem):\n",
    "            for i in range(len(ranklist)):\n",
    "                item = ranklist[i]\n",
    "                if item == targetItem:\n",
    "                    return math.log(2) / math.log(i+2)\n",
    "            return 0\n",
    "\n",
    "\n",
    "        hr =[]\n",
    "        NDCG = []\n",
    "        testUser = self.testNeg[0]\n",
    "        testItem = self.testNeg[1]\n",
    "        for i in range(len(testUser)):\n",
    "            target = testItem[i][0]\n",
    "            feed_dict = self.create_feed_dict(testUser[i], testItem[i])\n",
    "            predict = sess.run(self.y_, feed_dict=feed_dict)\n",
    "\n",
    "            item_score_dict = {}\n",
    "\n",
    "            for j in range(len(testItem[i])):\n",
    "                item = testItem[i][j]\n",
    "                item_score_dict[item] = predict[j]\n",
    "\n",
    "            ranklist = heapq.nlargest(topK, item_score_dict, key=item_score_dict.get)\n",
    "\n",
    "            tmp_hr = getHitRatio(ranklist, target)\n",
    "            tmp_NDCG = getNDCG(ranklist, target)\n",
    "            hr.append(tmp_hr)\n",
    "            NDCG.append(tmp_NDCG)\n",
    "        return np.mean(hr), np.mean(NDCG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "Loading ml-1m data set...\n",
      "Loading Success!\n",
      "Data Info:\n",
      "\tUser Num: 6040\n",
      "\tItem Num: 3952\n",
      "\tData Size: 1000209\n",
      "WARNING:tensorflow:From <ipython-input-14-b38f374f0183>:71: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From C:\\Users\\618757\\Anaconda3\\envs\\mypika\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "3\n",
      "Start Training!\n",
      "====================Epoch  0 ====================\n",
      "31060 / 31068 : loss = 47.008769989013674\n",
      "Mean loss in this epoch is: 47.359230041503906\n",
      "==================================================\n",
      "Start Evaluation!\n",
      "Epoch  0 HR: 0.641887417218543, NDCG: 0.37758967751604855\n",
      "====================Epoch  0 End====================\n",
      "====================Epoch  1 ====================\n",
      "31060 / 31068 : loss = 43.854309082031254\n",
      "Mean loss in this epoch is: 45.64255905151367\n",
      "==================================================\n",
      "Start Evaluation!\n",
      "Epoch  1 HR: 0.6529801324503312, NDCG: 0.3814556486626001\n",
      "====================Epoch  1 End====================\n",
      "====================Epoch  2 ====================\n",
      "31060 / 31068 : loss = 45.681198120117194\n",
      "Mean loss in this epoch is: 45.22483444213867\n",
      "==================================================\n",
      "Start Evaluation!\n",
      "Epoch  2 HR: 0.6543046357615894, NDCG: 0.3835920344301167\n",
      "====================Epoch  2 End====================\n",
      "====================Epoch  3 ====================\n",
      "31060 / 31068 : loss = 48.182731628417974\n",
      "Mean loss in this epoch is: 45.0384407043457\n",
      "==================================================\n",
      "Start Evaluation!\n",
      "Epoch  3 HR: 0.6574503311258278, NDCG: 0.38452031951451027\n",
      "====================Epoch  3 End====================\n",
      "====================Epoch  4 ====================\n",
      "31060 / 31068 : loss = 49.734516143798836\n",
      "Mean loss in this epoch is: 44.87970733642578\n",
      "==================================================\n",
      "Start Evaluation!\n",
      "Epoch  4 HR: 0.6582781456953642, NDCG: 0.3836994608241767\n",
      "====================Epoch  4 End====================\n",
      "Best hr: 0.6582781456953642, NDCG: 0.3836994608241767, At Epoch 4\n",
      "Training complete!\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "print('2')\n",
    "classifier = Model()\n",
    "print('3')\n",
    "classifier.run()\n",
    "print('4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mypika",
   "language": "python",
   "name": "mypika"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
